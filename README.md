**Proyecto Final â€“ AnÃ¡lisis y DiseÃ±o de Algoritmos I**
**ğŸ§  ImplementaciÃ³n de una red neuronal MLP desde cero (NumPy) + Bot de Control Remoto**
Este proyecto implementa una red neuronal multicapa (MLP) desde cero utilizando exclusivamente NumPy, con el fin de aplicar los Resultados de Aprendizaje (RA1, RA2 y RA3) del curso AnÃ¡lisis y DiseÃ±o de Algoritmos I.
AdemÃ¡s, se desarrollÃ³ un bot de Telegram que permite controlar el sistema de forma remota, facilitando la ejecuciÃ³n de comandos, la evaluaciÃ³n del modelo y la generaciÃ³n de reportes desde una interfaz conversacional.

El sistema se ejecuta completamente desde consola o mediante el bot, y permite entrenar, evaluar y analizar una red neuronal sobre el dataset MNIST (reconocimiento de dÃ­gitos manuscritos).

**âš™ï¸ CaracterÃ­sticas principales**
- RA1: ImplementaciÃ³n y validaciÃ³n matemÃ¡tica de un MLP.

- RA2: AnÃ¡lisis de eficiencia de algoritmos de selecciÃ³n top-k (sort, heap, quickselect).

- RA3: Estrategias de optimizaciÃ³n:

- RegularizaciÃ³n L2 (weight decay)

- Early stopping

- Hard-mining (minerÃ­a de ejemplos difÃ­ciles)

- Pruning (poda de ejemplos fÃ¡ciles)

- IntegraciÃ³n adicional:

- Bot de Telegram: Control remoto de entrenamiento, evaluaciÃ³n y anÃ¡lisis.

- AutomatizaciÃ³n remota: EjecuciÃ³n de comandos sin necesidad de abrir la consola.

- Evidencias adicionales:

- Prueba de estabilidad (semillas distintas)

- Ablation test (comparaciÃ³n con y sin regularizaciÃ³n)

- GrÃ¡ficas automÃ¡ticas de pÃ©rdida y accuracy

-  CSV (confusion matrix, accuracy por clase)

**ğŸ“‚ Estructura del proyecto**
Proyecto_ADA_Final/
â”œâ”€â”€ .venv/                      # Entorno virtual
â”œâ”€â”€ data/                       # Dataset MNIST comprimido
â”œâ”€â”€ results/                    # Resultados de entrenamiento y reportes
â”‚   â”œâ”€â”€ ra1_regularizado/
â”‚   â”œâ”€â”€ ra3_hardmine/
â”‚   â”œâ”€â”€ ra3_prune20/
â”‚   â”œâ”€â”€ report_regularizado/
â”‚   â”œâ”€â”€ seed0, seed1, seed2/
â”‚   â”œâ”€â”€ ablation_con_reg/
â”‚   â”œâ”€â”€ ablation_sin_reg/
â”‚   â”œâ”€â”€ test_bot/               # Resultados generados desde el bot
â”‚   â”œâ”€â”€ summary_seeds.csv
â”‚   â””â”€â”€ summary_seeds.png
â”‚
â”œâ”€â”€ proyecto_adA_console.py     # CÃ³digo principal (CLI)
â”œâ”€â”€ bot_ada.py                  # Bot de Telegram para control remoto
â”œâ”€â”€ graficar_logs.py            # Script de grÃ¡ficos (loss y accuracy)
â”œâ”€â”€ resumen_semillas.py         # Script de estabilidad
â”œâ”€â”€ .env                        # Variables del bot (TOKEN, USER_ID)
â”œâ”€â”€ README.md                   # Este archivo
â””â”€â”€ Informe_Final_ADA_Proyecto_Bot.docx

**ğŸ§© Requisitos**
Python 3.10+

**LibrerÃ­as necesarias:**
pip install numpy pandas matplotlib python-telegram-bot python-dotenv

**â–¶ï¸ EjecuciÃ³n del Proyecto (versiÃ³n consola)**
**1ï¸âƒ£ Descargar dataset MNIST**
python proyecto_adA_console.py download --out data/mnist.npz

**2ï¸âƒ£ Entrenar modelo final (regularizado)**
python proyecto_adA_console.py train --data data/mnist.npz --epochs 20 --batch 64 --hidden 128 --lr 0.1 --weight_decay 0.0005 --patience 3 --save_best --out results/ra1_regularizado

**3ï¸âƒ£ Evaluar modelo**
python proyecto_adA_console.py eval --data data/mnist.npz --weights results/ra1_regularizado/best_weights.npz

**4ï¸âƒ£ Generar reportes de mÃ©tricas**
python proyecto_adA_console.py eval_report --data data/mnist.npz --weights results/ra1_regularizado/best_weights.npz --out results/report_regularizado

**5ï¸âƒ£ Inferencia (predicciÃ³n individual)**
python proyecto_adA_console.py predict_idx --data data/mnist.npz --weights results/ra1_regularizado/best_weights.npz --index 123

**6ï¸âƒ£ Benchmark de eficiencia (RA2)**
python proyecto_adA_console.py bench

**7ï¸âƒ£ VerificaciÃ³n de gradientes (RA1)**
python proyecto_adA_console.py gradcheck

**ğŸ’¬ Control remoto con Bot de Telegram**

**1. ConfiguraciÃ³n del archivo .env**
Cree un archivo .env en la raÃ­z del proyecto con el siguiente formato:

TELEGRAM_BOT_TOKEN=su_token_de_bot
ALLOWED_USER_ID=su_user_id

**Ejemplo:**
TELEGRAM_BOT_TOKEN=7331133962:AAEtthWxr_GwMbIR6yLbhNw1VfcMRmM98dI
ALLOWED_USER_ID=1306756911

**2. EjecuciÃ³n del bot**
Active el entorno virtual y ejecute:
python bot_ada.py

El sistema mostrarÃ¡:
ğŸ¤– Bot ADA iniciado correctamente. Escribe /start en Telegram.

**3. InteracciÃ³n con el bot**
Abra Telegram y busque su bot (por ejemplo: @proyecto_ada_bot).
Luego escriba /start para ver los comandos disponibles.

| **Comando**  | **DescripciÃ³n**                                  |
| ------------ | ------------------------------------------------ |
| `/download`  | Descarga el dataset MNIST.                       |
| `/train`     | Entrena el modelo de red neuronal.               |
| `/eval`      | EvalÃºa el modelo entrenado.                      |
| `/report`    | Genera la matriz de confusiÃ³n y mÃ©tricas.        |
| `/predict`   | Realiza una predicciÃ³n de un dÃ­gito por Ã­ndice.  |
| `/bench`     | Ejecuta el benchmark de algoritmos RA2/RA3.      |
| `/gradcheck` | Verifica los gradientes por diferencias finitas. |
| `/whoami`    | Muestra el ID del usuario autorizado.            |

**Ejemplo de interacciÃ³n:**
Al escribir /train data/mnist.npz 3 64 128 0.1 results/test_bot, el bot entrena la red y responde con los resultados del entrenamiento directamente en el chat.

**ğŸ“ˆ Visualizaciones y anÃ¡lisis**
Curvas de entrenamiento

**Generadas con:**
python graficar_logs.py results/ra1_regularizado/train_log.csv

**Produce:**
loss_curve.png
accuracy_curve.png

**Estabilidad (semillas):**
python resumen_semillas.py

**Produce:**
results/summary_seeds.csv
results/summary_seeds.png

**ComparaciÃ³n con/sin regularizaciÃ³n (Ablation):**
python graficar_logs.py results/ablation_con_reg/train_log.csv
python graficar_logs.py results/ablation_sin_reg/train_log.csv

| **Experimento**    |**PrecisiÃ³n test_acc**| **ObservaciÃ³n**                      |
| ------------------ | -------------------- | ------------------------------------ |
| RA1 â€“ Base MLP     | 0.9618               | ImplementaciÃ³n base sin optimizaciÃ³n |
| RA2 â€“ Benchmark    | Heap 0.004s          | MÃ¡s eficiente que sort y quickselect |
| RA3 â€“ Regularizado | 0.9786               | Mejor generalizaciÃ³n y estabilidad   |
| Hard-mining        | 0.952                | Foco en ejemplos difÃ­ciles           |
| Poda 20%           | 0.962                | ReducciÃ³n de ejemplos simples        |
| Promedio semillas  | 0.9775 Â± 0.0006      | Alta estabilidad entre corridas      |

**ğŸ§¾ Conclusiones**

- Se logrÃ³ implementar un MLP desde cero, demostrando dominio en optimizaciÃ³n, gradientes y estructuras algorÃ­tmicas.

- La eficiencia de los algoritmos top-k fue validada experimentalmente.

- Las estrategias de regularizaciÃ³n, poda y hard-mining mejoraron el rendimiento sin sobreajuste.

- El bot de Telegram permitiÃ³ extender la funcionalidad del sistema, haciendo posible el control remoto de todo el flujo  de entrenamiento y evaluaciÃ³n.

- El modelo final alcanzÃ³ 97.8 % de precisiÃ³n y estabilidad de Â±0.0006, cumpliendo satisfactoriamente los objetivos del curso.

**ğŸ‘¨â€ğŸ’» Autor**

**SebastiÃ¡n GarcÃ­a Cruz**
TecnologÃ­a en Desarrollo de Software â€“ Universidad del Valle
CÃ³digo: 202269409
Correo: CreMoly70@gmail.com
Fecha: Noviembre de 2025
Lenguaje: Python 3.11
IDE: Visual Studio Code
EjecuciÃ³n: Consola / PowerShell / Telegram Bot